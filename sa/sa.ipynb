{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_wholesale = pd.read_csv('../Notebooks/experiment/curr_data.csv')\n",
    "historical_data_buyback = pd.read_csv('../Notebooks/experiment/curr_data_bb.csv')\n",
    "historical_data_revenue_sharing = pd.read_csv('../Notebooks/experiment/curr_data_rs.csv')\n",
    "behavioral_data = pd.read_csv('../adjusted_reponse_survey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_data.columns = behavioral_data.columns.str.strip()\n",
    "historical_data_wholesale.columns = historical_data_wholesale.columns.str.strip()\n",
    "historical_data_buyback.columns = historical_data_buyback.columns.str.strip()\n",
    "historical_data_revenue_sharing.columns = historical_data_revenue_sharing.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_wholesale.columns = historical_data_wholesale.columns.str.replace(' ', '_')\n",
    "historical_data_buyback.columns = historical_data_buyback.columns.str.replace(' ', '_')\n",
    "historical_data_revenue_sharing.columns = historical_data_revenue_sharing.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize retailer behavior based on stock and optimal stock\n",
    "def categorize_behavior(row):\n",
    "    \"\"\"\n",
    "    Categorizes retailer behavior as understocking, optimal, or overstocking.\n",
    "\n",
    "    Args:\n",
    "        row: A row from the historical data DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        An integer representing the behavioral category:\n",
    "        0: Understocking (Stock < Optimal * 0.8)\n",
    "        1: Optimal Stocking (Optimal * 0.8 <= Stock <= Optimal * 1.2)\n",
    "        2: Overstocking (Stock > Optimal * 1.2)\n",
    "    \"\"\"\n",
    "    stock = row['Stock']\n",
    "    optimal_stock = row[\"Optimal_Stock\"]\n",
    "\n",
    "    try:\n",
    "        optimal_stock = float(optimal_stock)  # Try converting to float\n",
    "    except ValueError:\n",
    "        optimal_stock = 0  # Set to 0 if conversion fails\n",
    "\n",
    "    if stock < optimal_stock * 0.8:\n",
    "        return 0  # Understocking\n",
    "    \n",
    "    elif stock <= optimal_stock * 1.2:\n",
    "        return 1  # Optimal Stocking\n",
    "    \n",
    "    else:\n",
    "        return 2  # Overstocking\n",
    "\n",
    "# Apply categorization to each dataset\n",
    "historical_data_wholesale['Behavioral_Category'] = historical_data_wholesale.apply(categorize_behavior, axis=1)\n",
    "historical_data_buyback['Behavioral_Category'] = historical_data_buyback.apply(categorize_behavior, axis=1)\n",
    "historical_data_revenue_sharing['Behavioral_Category'] = historical_data_revenue_sharing.apply(categorize_behavior, axis=1)\n",
    "\n",
    "# 2. Remove Extra 'Behavioral_Category' Columns\n",
    "def remove_extra_columns(df, column_name):\n",
    "    \"\"\"Removes extra columns with the given name, keeping only the last one.\"\"\"\n",
    "    cols = df.columns.tolist()\n",
    "    count = cols.count(column_name)\n",
    "    if count > 1:\n",
    "        indices = [i for i, x in enumerate(cols) if x == column_name]\n",
    "        for i in indices[:-1]:  # Remove all but the last one\n",
    "            df.drop(df.columns[i], axis=1, inplace=True)\n",
    "\n",
    "remove_extra_columns(historical_data_wholesale, \"Behavioral_Category\")\n",
    "remove_extra_columns(historical_data_buyback, \"Behavioral_Category\")\n",
    "remove_extra_columns(historical_data_revenue_sharing, \"Behavioral_Category\")\n",
    "\n",
    "# Save the updated data\n",
    "historical_data_wholesale.to_csv('../Notebooks/experiment/curr_data.csv', index=False)\n",
    "historical_data_buyback.to_csv('../Notebooks/experiment/curr_data_bb.csv', index=False)\n",
    "historical_data_revenue_sharing.to_csv('../Notebooks/experiment/curr_data_rs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Trait Extraction ---\n",
    "def extract_traits(behavioral_data):\n",
    "    \"\"\"\n",
    "    Extract traits for all manufacturers and retailers from the behavioral data.\n",
    "    Returns dictionaries of traits for manufacturers and retailers indexed by PLAYER NAME.\n",
    "    \"\"\"\n",
    "    manufacturers = behavioral_data[[\n",
    "        'Manufacturer_Self Esteem Average',\n",
    "        'Manufacturer_Regret Scale Average',\n",
    "        'Manufacturer_Risk Averse Coefficient',\n",
    "        'Manufacturer_Fairness Index'\n",
    "    ]].rename(lambda col: col.replace('Manufacturer_', ''), axis=1)\n",
    "\n",
    "    retailers = behavioral_data[[\n",
    "        'Retailer_Self Esteem Average',\n",
    "        'Retailer_Regret Scale Average',\n",
    "        'Retailer_Risk Averse Coefficient',\n",
    "        'Retailer_Fairness Index'\n",
    "    ]].rename(lambda col: col.replace('Retailer_', ''), axis=1)\n",
    "\n",
    "    # Return as dictionaries indexed by PLAYER NAME\n",
    "    manufacturer_traits = manufacturers.to_dict(orient='index')\n",
    "    retailer_traits = retailers.to_dict(orient='index')\n",
    "\n",
    "    return manufacturer_traits, retailer_traits\n",
    "\n",
    "# Extract Traits\n",
    "manufacturer_traits_dict, retailer_traits_dict = extract_traits(behavioral_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_demand = np.arange(50, 151)  # Possible demand values from 50 to 150\n",
    "stock_list = np.arange(50, 151)       # Possible stock values from 50 to 150\n",
    "expected_sales = {}                   # Dictionary to store expected sales\n",
    "\n",
    "\n",
    "for stock in stock_list:\n",
    "    cumulative_expected_sales = 0\n",
    "    for demand_realization in potential_demand:\n",
    "        sales = min(demand_realization, stock)\n",
    "        cumulative_expected_sales += sales\n",
    "\n",
    "    # Calculate the average sales and store it in the dictionary\n",
    "    expected_sales[stock] = cumulative_expected_sales / len(potential_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from gym import Env, spaces\n",
    "import random\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "# --- Environment Definition ---\n",
    "\n",
    "class SupplyChainEnv(Env):\n",
    "    \"\"\"\n",
    "    Custom Environment for the supply chain game.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, contract_type=\"wholesale\", expected_sales=None):\n",
    "        super(SupplyChainEnv, self).__init__()\n",
    "        self.contract_type = contract_type\n",
    "        self.max_stock = 150\n",
    "        self.min_w = 3  # Minimum wholesale price\n",
    "        self.max_price = 12\n",
    "        self.max_rounds = 40\n",
    "        self.current_round = 0\n",
    "        self.demand = 0  # Initialize demand\n",
    "        self.expected_sales = expected_sales  # Initialize expected sales\n",
    "\n",
    "        if self.contract_type == \"wholesale\":\n",
    "            self.manufacturer_action_space = spaces.Discrete(\n",
    "                self.max_price - self.min_w + 1\n",
    "            )\n",
    "            self.retailer_action_space = spaces.Discrete(3)  # Under, Optimal, Over\n",
    "        elif self.contract_type == \"buyback\":\n",
    "            self.manufacturer_action_space = spaces.MultiDiscrete(\n",
    "                [self.max_price - self.min_w + 1, self.max_price + 1]\n",
    "            )\n",
    "            self.retailer_action_space = spaces.Discrete(3)  # Under, Optimal, Over\n",
    "        elif self.contract_type == \"revenue-sharing\":\n",
    "            self.manufacturer_action_space = spaces.MultiDiscrete(\n",
    "                [self.max_price - self.min_w + 1, self.max_price + 1]\n",
    "            )\n",
    "            self.retailer_action_space = spaces.Discrete(3)  # Under, Optimal, Over\n",
    "        else:\n",
    "            raise ValueError(\"Invalid contract type.\")\n",
    "\n",
    "        # The state does not include the demand since it's unknown before decisions are made\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=150, shape=(3,), dtype=np.float32\n",
    "        )\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # At reset, we do not generate demand or include it in the state\n",
    "        self.state = np.array([0, 0, 0])  # State: [Wholesale Price, Buyback Price, Revenue Share]\n",
    "        self.current_round = 0\n",
    "        self.demand = 0\n",
    "        return self.state\n",
    "\n",
    "    def manufacturer_step(self, action):\n",
    "        # Unpack actions based on contract type\n",
    "        if self.contract_type == \"wholesale\":\n",
    "            w = action + self.min_w  # Adjust w to be in the correct range\n",
    "            b = 0\n",
    "            r = 0\n",
    "        elif self.contract_type == \"buyback\":\n",
    "            w = action[0] + self.min_w  # Adjust w\n",
    "            b = action[1]\n",
    "            r = 0\n",
    "        elif self.contract_type == \"revenue-sharing\":\n",
    "            w = action[0] + self.min_w  # Adjust w\n",
    "            r = action[1]\n",
    "            b = 0\n",
    "\n",
    "        # Update state with manufacturer's action\n",
    "        self.state = np.array([w, b, r])\n",
    "\n",
    "        return self.state\n",
    "    \n",
    "    def get_optimal_stock(self):\n",
    "        # Helper function to calculate optimal stock based on the current state\n",
    "        w, b, r = self.state\n",
    "\n",
    "        if self.contract_type == \"wholesale\":\n",
    "            optimal_stock = 100 * ((12 - w) / 12) + 50\n",
    "        elif self.contract_type == \"buyback\":\n",
    "            if b == 12:\n",
    "                optimal_stock = 150\n",
    "            else:\n",
    "                optimal_stock = 100 * ((12 - w) / (12 - b)) + 50\n",
    "        elif self.contract_type == \"revenue-sharing\":\n",
    "            if r == 12:\n",
    "                optimal_stock = 0\n",
    "            else:\n",
    "                optimal_stock = 100 * ((12 - w - r) / (12 - r)) + 50\n",
    "        else:\n",
    "            optimal_stock = 100\n",
    "\n",
    "        return optimal_stock\n",
    "\n",
    "    def retailer_step(self, action):\n",
    "        # Determine optimal stock based on contract type and current w, b, r\n",
    "        w, b, r = self.state\n",
    "\n",
    "        if self.contract_type == \"wholesale\":\n",
    "            optimal_stock = 100 * ((12 - w) / 12) + 50\n",
    "        elif self.contract_type == \"buyback\":\n",
    "            if b == 12:  # Division by zero\n",
    "                optimal_stock = 150  # Set to maximum\n",
    "            else:\n",
    "                optimal_stock = 100 * ((12 - w) / (12 - b)) + 50\n",
    "        elif self.contract_type == \"revenue-sharing\":\n",
    "            if r == 12:  # Division by zero\n",
    "                optimal_stock = 0  # Set to minimum\n",
    "            else:\n",
    "                optimal_stock = 100 * ((12 - w - r) / (12 - r)) + 50\n",
    "        else:\n",
    "            optimal_stock = 100  # default\n",
    "\n",
    "        # Determine retailer's order quantity based on action (0: under, 1: optimal, 2: over)\n",
    "        if action == 0:\n",
    "            Q = optimal_stock * 0.8\n",
    "        elif action == 1:\n",
    "            Q = optimal_stock\n",
    "        elif action == 2:\n",
    "            Q = optimal_stock * 1.2\n",
    "        else:\n",
    "            Q = optimal_stock  # default\n",
    "\n",
    "        Q = int(round(Q))  # Round Q to the nearest integer\n",
    "        Q = max(0, min(Q, self.max_stock))  # Ensure Q is within bounds\n",
    "\n",
    "        # Use expected sales for profit calculation\n",
    "        sales = self.expected_sales.get(Q, 0)\n",
    "        leftovers = Q - sales\n",
    "        c = 3  # Manufacturer's production cost\n",
    "        p = 12  # Retail price\n",
    "\n",
    "        if self.contract_type == \"wholesale\":\n",
    "            # Retailer expected profit\n",
    "            retailer_profit = p * sales - w * Q\n",
    "\n",
    "            # Manufacturer expected profit\n",
    "            manufacturer_profit = (w - c) * Q\n",
    "\n",
    "        elif self.contract_type == \"buyback\":\n",
    "            # Enforce constraint: buyback price must not exceed wholesale price\n",
    "            if b > w:\n",
    "                b = w\n",
    "\n",
    "            # Retailer expected profit\n",
    "            retailer_profit = p * sales - w * Q + b * leftovers\n",
    "\n",
    "            # Manufacturer expected profit\n",
    "            manufacturer_profit = (w - c) * Q - b * leftovers\n",
    "\n",
    "        elif self.contract_type == \"revenue-sharing\":\n",
    "            # Enforce constraint: revenue share must not exceed (retail price - wholesale price)\n",
    "            max_revenue_share = p - w\n",
    "            if r > max_revenue_share:\n",
    "                r = max_revenue_share\n",
    "\n",
    "            # Retailer expected profit\n",
    "            retailer_profit = (p - r) * sales - w * Q\n",
    "\n",
    "            # Manufacturer expected profit\n",
    "            manufacturer_profit = (w - c) * Q + r * sales\n",
    "\n",
    "\n",
    "\n",
    "        # Generate demand\n",
    "        # self.demand = np.random.randint(50, 151)\n",
    "\n",
    "        # # Calculate sales and leftovers based on actual demand\n",
    "        # sales = min(Q, self.demand)\n",
    "        # leftovers = Q - sales\n",
    "\n",
    "        # if self.contract_type == \"wholesale\":\n",
    "        #     # Retailer and manufacturer actual profit\n",
    "        #     realized_retailer_profit = p * sales - w * Q\n",
    "        #     realized_manufacturer_profit = (w - c) * Q\n",
    "\n",
    "        # elif self.contract_type == \"buyback\":\n",
    "        #     # Retailer and manufacturer actual profit\n",
    "        #     realized_retailer_profit = p * sales - w * Q + b * leftovers\n",
    "        #     realized_manufacturer_profit = (w - c) * Q - b * leftovers\n",
    "\n",
    "        # elif self.contract_type == \"revenue-sharing\":\n",
    "        #     # Retailer and manufacturer actual profit\n",
    "        #     realized_retailer_profit = (p - r) * sales - w * Q\n",
    "        #     realized_manufacturer_profit = (w - c) * Q + r * sales\n",
    "        # else:\n",
    "        #     realized_retailer_profit = 0\n",
    "        #     realized_manufacturer_profit = 0\n",
    "\n",
    "        self.current_round += 1\n",
    "        done = self.current_round >= self.max_rounds\n",
    "\n",
    "        # Return next_state, rewards (expected profits), done, info\n",
    "        return self.state, (manufacturer_profit, retailer_profit), done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Definition ---\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        action_space,\n",
    "        personality_traits=None,\n",
    "        learning_rate=0.1,\n",
    "        discount_factor=0.99,\n",
    "        epsilon=1.0,\n",
    "        epsilon_decay=0.995,\n",
    "        min_epsilon=0.01,\n",
    "    ):\n",
    "        self.action_space = action_space\n",
    "        self.personality_traits = personality_traits or {}\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_epsilon = epsilon  # Store initial epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.q_table = defaultdict(float)\n",
    "        self.estimated_human_traits = {\n",
    "            \"Risk Averse Coefficient\": 0.5,\n",
    "            \"Fairness Index\": 0.5,\n",
    "            \"Regret Scale Average\": 0.0,\n",
    "            \"Self Esteem Average\": 0.0,\n",
    "        }\n",
    "        self.human_actions = []\n",
    "        self.behavior_change_threshold = 2\n",
    "        self.opponent_trait_estimates = {\n",
    "            \"Risk Averse Coefficient\": 0.5,  # Initial guess\n",
    "            \"Fairness Index\": 0.5,  # Initial guess\n",
    "            \"Regret Scale Average\": 0.0,\n",
    "            \"Self Esteem Average\": 0.0,\n",
    "        }\n",
    "        self.opponent_action_history = []  # Keep track of opponent actions\n",
    "        self.last_round_prof = 0\n",
    "\n",
    "    def _state_to_key(self, state):\n",
    "        trait_values = tuple(self.personality_traits.values())\n",
    "        return tuple(state) + trait_values\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if self.detect_behavior_change():\n",
    "            self.epsilon = min(1.0, self.epsilon * 1.1)  # Increase epsilon to promote exploration\n",
    "        else:\n",
    "            # Risk-averse agents explore less\n",
    "            risk_aversion = self.personality_traits.get(\"Risk Averse Coefficient\", 0.5)\n",
    "            self.epsilon = max(\n",
    "                self.min_epsilon,\n",
    "                self.epsilon * self.epsilon_decay * (1 - risk_aversion),\n",
    "            )\n",
    "\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore: choose a random action\n",
    "            if isinstance(self.action_space, spaces.Discrete):\n",
    "                return self.action_space.sample()\n",
    "            elif isinstance(self.action_space, spaces.MultiDiscrete):\n",
    "                return tuple(self.action_space.sample())\n",
    "        else:\n",
    "            # Exploit: choose the action with the highest Q-value\n",
    "            state_key = self._state_to_key(state)\n",
    "            possible_actions = self.get_possible_actions()\n",
    "            q_values = [self.q_table[(state_key, a)] for a in possible_actions]\n",
    "            max_q = max(q_values)\n",
    "            max_actions = [a for a, q in zip(possible_actions, q_values) if q == max_q]\n",
    "            chosen_action = random.choice(max_actions)\n",
    "            return chosen_action\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        state_key = self._state_to_key(state)\n",
    "        next_state_key = self._state_to_key(next_state)\n",
    "\n",
    "        # Get possible actions for next state\n",
    "        possible_actions = self.get_possible_actions()\n",
    "        max_next_q = max(\n",
    "            [self.q_table[(next_state_key, a)] for a in possible_actions], default=0\n",
    "        )\n",
    "\n",
    "        # Adjust the reward based on estimated human traits and opponent traits\n",
    "        adjusted_reward = self.adjust_reward_based_on_traits(reward)\n",
    "\n",
    "        # Update Q-value using the adjusted reward\n",
    "        self.q_table[(state_key, action)] += self.learning_rate * (\n",
    "            adjusted_reward\n",
    "            + self.discount_factor * max_next_q\n",
    "            - self.q_table[(state_key, action)]\n",
    "        )\n",
    "\n",
    "    def update_estimated_human_traits(self, human_action):\n",
    "        self.human_actions.append(human_action)\n",
    "        if len(self.human_actions) > 10:\n",
    "            recent_actions = self.human_actions[-10:]\n",
    "            action_variance = np.var(recent_actions)\n",
    "            max_variance = (\n",
    "                (self.action_space.n - 1) ** 2 / 12\n",
    "            )  # Variance of a uniform distribution\n",
    "            self.estimated_human_traits[\"Risk Averse Coefficient\"] = max(\n",
    "                0, min(1, 1 - action_variance / max_variance)\n",
    "            )\n",
    "\n",
    "    def adjust_reward_based_on_traits(self, reward, other_agent_reward=0):\n",
    "        risk_aversion = self.personality_traits.get(\"Risk Averse Coefficient\", 0.5)\n",
    "        fairness = self.personality_traits.get(\"Fairness Index\", 0.0)\n",
    "        regret_scale = self.personality_traits.get(\"Regret Scale Average\", 0.0)\n",
    "        self_esteem = self.personality_traits.get(\"Self Esteem Average\", 0.0)\n",
    "\n",
    "        # Use opponent trait estimates in reward shaping\n",
    "        opponent_risk_aversion = self.opponent_trait_estimates[\"Risk Averse Coefficient\"]\n",
    "\n",
    "        # Risk-based adjustment\n",
    "        risk_adjusted_reward = reward * (\n",
    "            1.0 + (0.5 - risk_aversion)\n",
    "        ) - (1.0 * opponent_risk_aversion)\n",
    "\n",
    "        # Fairness-based adjustment\n",
    "        fairness_adjusted_reward = risk_adjusted_reward + (fairness * other_agent_reward)\n",
    "\n",
    "        # Regret-based adjustment\n",
    "        regret_adjusted_reward = fairness_adjusted_reward - (regret_scale * (self.last_round_prof))\n",
    "\n",
    "        # Self-esteem-based adjustment (example)\n",
    "        # High self-esteem might lead to overconfidence, so slightly reduce reward\n",
    "        self_esteem_adjusted_reward = regret_adjusted_reward * (\n",
    "            1.0 - (self_esteem * 0.1)\n",
    "        )\n",
    "\n",
    "        self.last_round_prof = reward\n",
    "\n",
    "        return self_esteem_adjusted_reward\n",
    "\n",
    "    def detect_behavior_change(self):\n",
    "        if len(self.human_actions) < 20:\n",
    "            return False\n",
    "        recent_actions = self.human_actions[-10:]\n",
    "        previous_actions = self.human_actions[-20:-10]\n",
    "        recent_mean = np.mean(recent_actions)\n",
    "        previous_mean = np.mean(previous_actions)\n",
    "        if abs(recent_mean - previous_mean) > self.behavior_change_threshold:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def get_possible_actions(self):\n",
    "        if isinstance(self.action_space, spaces.Discrete):\n",
    "            return range(self.action_space.n)\n",
    "        elif isinstance(self.action_space, spaces.MultiDiscrete):\n",
    "            ranges = [range(n) for n in self.action_space.nvec]\n",
    "            possible_actions = list(itertools.product(*ranges))\n",
    "            return possible_actions\n",
    "\n",
    "    def update_opponent_model(self, opponent_action, state, contract_type):\n",
    "        \"\"\"Updates estimates of the opponent's traits based on observed actions.\"\"\"\n",
    "        self.opponent_action_history.append((state, opponent_action))\n",
    "\n",
    "        # Heuristic for estimating risk aversion:\n",
    "        if contract_type == \"wholesale\":\n",
    "            optimal_stock = 100 * ((12 - state[0]) / 12) + 50\n",
    "        elif contract_type == \"buyback\":\n",
    "            optimal_stock = 100 * ((12 - state[0]) / (12 - state[1])) + 50\n",
    "        elif contract_type == \"revenue-sharing\":\n",
    "            optimal_stock = 100 * ((12 - state[0] - state[2]) / (12 - state[2])) + 50\n",
    "        else:\n",
    "            optimal_stock = 100\n",
    "\n",
    "        if opponent_action == 0:  # Understocking\n",
    "            self.opponent_trait_estimates[\"Risk Averse Coefficient\"] = min(\n",
    "                1.0, self.opponent_trait_estimates[\"Risk Averse Coefficient\"] + 0.1\n",
    "            )\n",
    "        elif opponent_action == 2:  # Overstocking\n",
    "            self.opponent_trait_estimates[\"Risk Averse Coefficient\"] = max(\n",
    "                0.0, self.opponent_trait_estimates[\"Risk Averse Coefficient\"] - 0.1\n",
    "            )\n",
    "\n",
    "        # Heuristics for other traits (examples):\n",
    "        # Fairness:\n",
    "        if contract_type == \"wholesale\":\n",
    "            if state[0] > 8:  # Manufacturer sets a high wholesale price\n",
    "                self.opponent_trait_estimates[\"Fairness Index\"] = max(\n",
    "                    0.0, self.opponent_trait_estimates[\"Fairness Index\"] - 0.1\n",
    "                )\n",
    "            elif state[0] < 5:  # Manufacturer sets a low wholesale price\n",
    "                self.opponent_trait_estimates[\"Fairness Index\"] = min(\n",
    "                    1.0, self.opponent_trait_estimates[\"Fairness Index\"] + 0.1\n",
    "                )\n",
    "\n",
    "        # Regret: (This is more complex, needs tracking of past actions and outcomes)\n",
    "        # You could, for example, increase the opponent's estimated regret if they repeat an action that previously led to a low reward.\n",
    "\n",
    "        # Self-Esteem: (This is also tricky)\n",
    "        # You could, for example, decrease the opponent's estimated self-esteem if they frequently change their actions,\n",
    "        # or increase it if they stick to the same action for several rounds.\n",
    "\n",
    "    def save_agent(self, filename):\n",
    "        \"\"\"Saves the agent's Q-table, opponent model parameters, and other attributes to a file.\"\"\"\n",
    "        agent_data = {\n",
    "            \"q_table\": self.q_table,\n",
    "            \"opponent_trait_estimates\": self.opponent_trait_estimates,\n",
    "            \"personality_traits\": self.personality_traits,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"discount_factor\": self.discount_factor,\n",
    "            \"epsilon\": self.epsilon,\n",
    "            \"initial_epsilon\": self.initial_epsilon,\n",
    "            \"epsilon_decay\": self.epsilon_decay,\n",
    "            \"min_epsilon\": self.min_epsilon,\n",
    "        }\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(agent_data, f)\n",
    "\n",
    "    def load_agent(self, filename):\n",
    "        \"\"\"Loads the agent's Q-table, opponent model parameters, and other attributes from a file.\"\"\"\n",
    "        with open(filename, \"rb\") as f:\n",
    "            agent_data = pickle.load(f)\n",
    "\n",
    "        self.q_table = agent_data[\"q_table\"]\n",
    "        self.opponent_trait_estimates = agent_data[\"opponent_trait_estimates\"]\n",
    "        self.personality_traits = agent_data[\"personality_traits\"]\n",
    "        self.learning_rate = agent_data[\"learning_rate\"]\n",
    "        self.discount_factor = agent_data[\"discount_factor\"]\n",
    "        self.epsilon = agent_data[\"epsilon\"]\n",
    "        self.initial_epsilon = agent_data[\"initial_epsilon\"]\n",
    "        self.epsilon_decay = agent_data[\"epsilon_decay\"]\n",
    "        self.min_epsilon = agent_data[\"min_epsilon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Historical Data Preprocessing ---\n",
    "\n",
    "def preprocess_historical_data(df, contract_type):\n",
    "    data = []\n",
    "    num_rows = len(df)\n",
    "    rows_per_game = 40\n",
    "\n",
    "    for start_row in range(0, num_rows, rows_per_game):\n",
    "        game_data = df.iloc[start_row : start_row + rows_per_game]\n",
    "        previous_state = None\n",
    "\n",
    "        for _, row in game_data.iterrows():\n",
    "            wholesale_price = float(row[\"Wholesale_p.\"])\n",
    "            buyback_price = (\n",
    "                float(row[\"Buyback_p.\"])\n",
    "                if \"Buyback_p.\" in row and not pd.isnull(row[\"Buyback_p.\"])\n",
    "                else 0.0\n",
    "            )\n",
    "            revenue_share = (\n",
    "                float(row[\"Revenue_Share\"])\n",
    "                if \"Revenue_Share\" in row and not pd.isnull(row[\"Revenue_Share\"])\n",
    "                else 0.0\n",
    "            )\n",
    "\n",
    "            # State variables: No previous retailer profit\n",
    "            state = [\n",
    "                wholesale_price,\n",
    "                buyback_price,\n",
    "                revenue_share\n",
    "            ]\n",
    "\n",
    "            # Actions\n",
    "            if contract_type == \"wholesale\":\n",
    "                manufacturer_action = wholesale_price - 3\n",
    "            elif contract_type == \"buyback\":\n",
    "                manufacturer_action = (wholesale_price - 3, buyback_price)\n",
    "            elif contract_type == \"revenue-sharing\":\n",
    "                manufacturer_action = (wholesale_price - 3, revenue_share)\n",
    "            else:\n",
    "                manufacturer_action = (wholesale_price - 3, 0.0)\n",
    "\n",
    "            retailer_action = int(row[\"Behavioral_Category\"])  # Convert to int\n",
    "\n",
    "            # Rewards (Using realized profits instead of expected)\n",
    "            try:\n",
    "                manufacturer_reward = float(row[\"Realized_Mfg_Profit\"])\n",
    "            except ValueError:\n",
    "                manufacturer_reward = 0\n",
    "\n",
    "            try:\n",
    "                retailer_reward = float(row[\"Realized_Retailer_Profit\"])\n",
    "            except ValueError:\n",
    "                retailer_reward = 0\n",
    "\n",
    "            # Next state: Use current values as next state for the next round\n",
    "            next_state = [\n",
    "                wholesale_price,\n",
    "                buyback_price,\n",
    "                revenue_share\n",
    "            ]\n",
    "\n",
    "            data.append(\n",
    "                (\n",
    "                    state,\n",
    "                    manufacturer_action,\n",
    "                    retailer_action,\n",
    "                    (manufacturer_reward, retailer_reward),\n",
    "                    next_state,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return data\n",
    "\n",
    "# Process Historical Data\n",
    "historical_data_wholesale = preprocess_historical_data(\n",
    "    historical_data_wholesale, \"wholesale\"\n",
    ")\n",
    "historical_data_buyback = preprocess_historical_data(\n",
    "    historical_data_buyback, \"buyback\"\n",
    ")\n",
    "historical_data_revenue_sharing = preprocess_historical_data(\n",
    "    historical_data_revenue_sharing, \"revenue-sharing\"\n",
    ")\n",
    "\n",
    "# Combine Historical Data\n",
    "historical_data = (\n",
    "    historical_data_wholesale\n",
    "    + historical_data_buyback\n",
    "    + historical_data_revenue_sharing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Initialization ---\n",
    "\n",
    "# Create an environment for each contract type\n",
    "env_wholesale = SupplyChainEnv(contract_type=\"wholesale\", expected_sales=expected_sales)\n",
    "env_buyback = SupplyChainEnv(contract_type=\"buyback\", expected_sales=expected_sales)\n",
    "env_revenue_sharing = SupplyChainEnv(\n",
    "    contract_type=\"revenue-sharing\", expected_sales=expected_sales\n",
    ")\n",
    "\n",
    "# Create 6 agents with specific traits\n",
    "# For simplicity, let's just use the first 6 from each trait dictionary\n",
    "manufacturer_traits = list(manufacturer_traits_dict.values())[:3]\n",
    "retailer_traits = list(retailer_traits_dict.values())[:3]\n",
    "\n",
    "manufacturer_agent_wholesale = QLearningAgent(\n",
    "    env_wholesale.manufacturer_action_space, personality_traits=manufacturer_traits[0]\n",
    ")\n",
    "retailer_agent_wholesale = QLearningAgent(\n",
    "    env_wholesale.retailer_action_space, personality_traits=retailer_traits[0]\n",
    ")\n",
    "\n",
    "manufacturer_agent_buyback = QLearningAgent(\n",
    "    env_buyback.manufacturer_action_space, personality_traits=manufacturer_traits[1]\n",
    ")\n",
    "retailer_agent_buyback = QLearningAgent(\n",
    "    env_buyback.retailer_action_space, personality_traits=retailer_traits[1]\n",
    ")\n",
    "\n",
    "manufacturer_agent_revenue_sharing = QLearningAgent(\n",
    "    env_revenue_sharing.manufacturer_action_space,\n",
    "    personality_traits=manufacturer_traits[2],\n",
    ")\n",
    "retailer_agent_revenue_sharing = QLearningAgent(\n",
    "    env_revenue_sharing.retailer_action_space, personality_traits=retailer_traits[2]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wholesale - Episode 1:\n",
      "  Total Manufacturer Profit: 14950\n",
      "  Total Retailer Profit: 9399.633663366338\n",
      "Wholesale - Episode 101:\n",
      "  Total Manufacturer Profit: 12599\n",
      "  Total Retailer Profit: 8728.980198019803\n",
      "Wholesale - Episode 201:\n",
      "  Total Manufacturer Profit: 12046\n",
      "  Total Retailer Profit: 12714.930693069302\n",
      "Wholesale - Episode 301:\n",
      "  Total Manufacturer Profit: 12929\n",
      "  Total Retailer Profit: 13576.237623762372\n",
      "Wholesale - Episode 401:\n",
      "  Total Manufacturer Profit: 13181\n",
      "  Total Retailer Profit: 10629.881188118814\n",
      "Wholesale - Episode 501:\n",
      "  Total Manufacturer Profit: 13339\n",
      "  Total Retailer Profit: 7059.90099009901\n",
      "Wholesale - Episode 601:\n",
      "  Total Manufacturer Profit: 12914\n",
      "  Total Retailer Profit: 8815.118811881192\n",
      "Wholesale - Episode 701:\n",
      "  Total Manufacturer Profit: 13537\n",
      "  Total Retailer Profit: 9577.94059405941\n",
      "Wholesale - Episode 801:\n",
      "  Total Manufacturer Profit: 11801\n",
      "  Total Retailer Profit: 13406.960396039603\n",
      "Wholesale - Episode 901:\n",
      "  Total Manufacturer Profit: 12749\n",
      "  Total Retailer Profit: 8829.31683168317\n",
      "Buyback - Episode 1:\n",
      "  Total Manufacturer Profit: -5979.831683168317\n",
      "  Total Retailer Profit: 35997.50495049505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Can\\AppData\\Local\\Temp\\ipykernel_6080\\2095580332.py:160: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  optimal_stock = 100 * ((12 - state[0]) / (12 - state[1])) + 50\n",
      "C:\\Users\\Can\\AppData\\Local\\Temp\\ipykernel_6080\\2095580332.py:160: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  optimal_stock = 100 * ((12 - state[0]) / (12 - state[1])) + 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buyback - Episode 101:\n",
      "  Total Manufacturer Profit: 2318.8910891089145\n",
      "  Total Retailer Profit: 27604.86138613862\n",
      "Buyback - Episode 201:\n",
      "  Total Manufacturer Profit: -674.4851485148515\n",
      "  Total Retailer Profit: 30380.18811881188\n",
      "Buyback - Episode 301:\n",
      "  Total Manufacturer Profit: -1636.455445544554\n",
      "  Total Retailer Profit: 31445.554455445545\n",
      "Buyback - Episode 401:\n",
      "  Total Manufacturer Profit: -4377.178217821782\n",
      "  Total Retailer Profit: 34410.44554455446\n",
      "Buyback - Episode 501:\n",
      "  Total Manufacturer Profit: 4199.544554455445\n",
      "  Total Retailer Profit: 24900.544554455446\n",
      "Buyback - Episode 601:\n",
      "  Total Manufacturer Profit: 11179.0\n",
      "  Total Retailer Profit: 17380.58415841584\n",
      "Buyback - Episode 701:\n",
      "  Total Manufacturer Profit: 811.3663366336632\n",
      "  Total Retailer Profit: 28213.099009900987\n",
      "Buyback - Episode 801:\n",
      "  Total Manufacturer Profit: 4313.425742574256\n",
      "  Total Retailer Profit: 24347.920792079207\n",
      "Buyback - Episode 901:\n",
      "  Total Manufacturer Profit: 11502.267326732672\n",
      "  Total Retailer Profit: 17575.81188118812\n",
      "Revenue Sharing - Episode 1:\n",
      "  Total Manufacturer Profit: 7657.198019801979\n",
      "  Total Retailer Profit: 1190.5742574257429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Can\\AppData\\Local\\Temp\\ipykernel_6080\\2095580332.py:162: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  optimal_stock = 100 * ((12 - state[0] - state[2]) / (12 - state[2])) + 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue Sharing - Episode 101:\n",
      "  Total Manufacturer Profit: 7680.346534653466\n",
      "  Total Retailer Profit: 2171.653465346535\n",
      "Revenue Sharing - Episode 201:\n",
      "  Total Manufacturer Profit: 10015.118811881188\n",
      "  Total Retailer Profit: 2867.742574257425\n",
      "Revenue Sharing - Episode 301:\n",
      "  Total Manufacturer Profit: 5483.039603960396\n",
      "  Total Retailer Profit: -930.0198019801982\n",
      "Revenue Sharing - Episode 401:\n",
      "  Total Manufacturer Profit: 7396.178217821783\n",
      "  Total Retailer Profit: 467.38613861386125\n",
      "Revenue Sharing - Episode 501:\n",
      "  Total Manufacturer Profit: 7425.247524752474\n",
      "  Total Retailer Profit: 4447.297029702971\n",
      "Revenue Sharing - Episode 601:\n",
      "  Total Manufacturer Profit: 7689.257425742574\n",
      "  Total Retailer Profit: 2153.7722772277225\n",
      "Revenue Sharing - Episode 701:\n",
      "  Total Manufacturer Profit: 6534.198019801979\n",
      "  Total Retailer Profit: 2619.0099009900987\n",
      "Revenue Sharing - Episode 801:\n",
      "  Total Manufacturer Profit: 7092.425742574256\n",
      "  Total Retailer Profit: 851.811881188119\n",
      "Revenue Sharing - Episode 901:\n",
      "  Total Manufacturer Profit: 9162.39603960396\n",
      "  Total Retailer Profit: 965.0693069306931\n"
     ]
    }
   ],
   "source": [
    "# --- Agent Training ---\n",
    "num_episodes = 1000  # You can increase this for more training\n",
    "\n",
    "# Train Wholesale Agents\n",
    "for episode in range(num_episodes):\n",
    "    state = env_wholesale.reset()\n",
    "    done = False\n",
    "    total_manufacturer_profit = 0\n",
    "    total_retailer_profit = 0\n",
    "\n",
    "    while not done:\n",
    "        manufacturer_action = manufacturer_agent_wholesale.get_action(state)\n",
    "        state = env_wholesale.manufacturer_step(manufacturer_action)\n",
    "\n",
    "        retailer_action = retailer_agent_wholesale.get_action(state)\n",
    "        next_state, rewards, done, _ = env_wholesale.retailer_step(retailer_action)\n",
    "\n",
    "        manufacturer_reward, retailer_reward = rewards\n",
    "        total_manufacturer_profit += manufacturer_reward\n",
    "        total_retailer_profit += retailer_reward\n",
    "\n",
    "        manufacturer_agent_wholesale.update_q_table(\n",
    "            state, manufacturer_action, manufacturer_reward, next_state\n",
    "        )\n",
    "        retailer_agent_wholesale.update_q_table(\n",
    "            state, retailer_action, retailer_reward, next_state\n",
    "        )\n",
    "\n",
    "        manufacturer_agent_wholesale.update_opponent_model(\n",
    "            retailer_action, state, env_wholesale.contract_type\n",
    "        )\n",
    "        retailer_agent_wholesale.update_opponent_model(\n",
    "            manufacturer_action, state, env_wholesale.contract_type\n",
    "        )\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    if episode % 100 == 0:\n",
    "        print(f\"Wholesale - Episode {episode + 1}:\")\n",
    "        print(f\"  Total Manufacturer Profit: {total_manufacturer_profit}\")\n",
    "        print(f\"  Total Retailer Profit: {total_retailer_profit}\")\n",
    "\n",
    "# Train Buyback Agents\n",
    "for episode in range(num_episodes):\n",
    "    state = env_buyback.reset()\n",
    "    done = False\n",
    "    total_manufacturer_profit = 0\n",
    "    total_retailer_profit = 0\n",
    "\n",
    "    while not done:\n",
    "        manufacturer_action = manufacturer_agent_buyback.get_action(state)\n",
    "        state = env_buyback.manufacturer_step(manufacturer_action)\n",
    "\n",
    "        retailer_action = retailer_agent_buyback.get_action(state)\n",
    "        next_state, rewards, done, _ = env_buyback.retailer_step(retailer_action)\n",
    "\n",
    "        manufacturer_reward, retailer_reward = rewards\n",
    "        total_manufacturer_profit += manufacturer_reward\n",
    "        total_retailer_profit += retailer_reward\n",
    "\n",
    "        manufacturer_agent_buyback.update_q_table(\n",
    "            state, manufacturer_action, manufacturer_reward, next_state\n",
    "        )\n",
    "        retailer_agent_buyback.update_q_table(\n",
    "            state, retailer_action, retailer_reward, next_state\n",
    "        )\n",
    "\n",
    "        manufacturer_agent_buyback.update_opponent_model(\n",
    "            retailer_action, state, env_buyback.contract_type\n",
    "        )\n",
    "        retailer_agent_buyback.update_opponent_model(\n",
    "            manufacturer_action, state, env_buyback.contract_type\n",
    "        )\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    if episode % 100 == 0:\n",
    "        print(f\"Buyback - Episode {episode + 1}:\")\n",
    "        print(f\"  Total Manufacturer Profit: {total_manufacturer_profit}\")\n",
    "        print(f\"  Total Retailer Profit: {total_retailer_profit}\")\n",
    "\n",
    "# Train Revenue Sharing Agents\n",
    "for episode in range(num_episodes):\n",
    "    state = env_revenue_sharing.reset()\n",
    "    done = False\n",
    "    total_manufacturer_profit = 0\n",
    "    total_retailer_profit = 0\n",
    "\n",
    "    while not done:\n",
    "        manufacturer_action = manufacturer_agent_revenue_sharing.get_action(state)\n",
    "        state = env_revenue_sharing.manufacturer_step(manufacturer_action)\n",
    "\n",
    "        retailer_action = retailer_agent_revenue_sharing.get_action(state)\n",
    "        next_state, rewards, done, _ = env_revenue_sharing.retailer_step(\n",
    "            retailer_action\n",
    "        )\n",
    "\n",
    "        manufacturer_reward, retailer_reward = rewards\n",
    "        total_manufacturer_profit += manufacturer_reward\n",
    "        total_retailer_profit += retailer_reward\n",
    "\n",
    "        manufacturer_agent_revenue_sharing.update_q_table(\n",
    "            state, manufacturer_action, manufacturer_reward, next_state\n",
    "        )\n",
    "        retailer_agent_revenue_sharing.update_q_table(\n",
    "            state, retailer_action, retailer_reward, next_state\n",
    "        )\n",
    "\n",
    "        manufacturer_agent_revenue_sharing.update_opponent_model(\n",
    "            retailer_action, state, env_revenue_sharing.contract_type\n",
    "        )\n",
    "        retailer_agent_revenue_sharing.update_opponent_model(\n",
    "            manufacturer_action, state, env_revenue_sharing.contract_type\n",
    "        )\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    if episode % 100 == 0:\n",
    "        print(f\"Revenue Sharing - Episode {episode + 1}:\")\n",
    "        print(f\"  Total Manufacturer Profit: {total_manufacturer_profit}\")\n",
    "        print(f\"  Total Retailer Profit: {total_retailer_profit}\")\n",
    "\n",
    "# --- Save Trained Agents ---\n",
    "\n",
    "manufacturer_agent_wholesale.save_agent(\"manufacturer_agent_wholesale.pkl\")\n",
    "retailer_agent_wholesale.save_agent(\"retailer_agent_wholesale.pkl\")\n",
    "manufacturer_agent_buyback.save_agent(\"manufacturer_agent_buyback.pkl\")\n",
    "retailer_agent_buyback.save_agent(\"retailer_agent_buyback.pkl\")\n",
    "manufacturer_agent_revenue_sharing.save_agent(\n",
    "    \"manufacturer_agent_revenue_sharing.pkl\"\n",
    ")\n",
    "retailer_agent_revenue_sharing.save_agent(\n",
    "    \"retailer_agent_revenue_sharing.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Round 1 ---\n",
      "  Manufacturer's wholesale price: 6\n",
      "  Demand in this round: 120\n",
      "  Your profit this round: 300\n",
      "  Agent's profit this round: 150\n",
      "  Your cumulative profit: 300\n",
      "  Agent's cumulative profit: 150\n",
      "\n",
      "--- Round 2 ---\n",
      "  Manufacturer's wholesale price: 5\n",
      "  Demand in this round: 133\n",
      "  Your profit this round: 350\n",
      "  Agent's profit this round: 100\n",
      "  Your cumulative profit: 650\n",
      "  Agent's cumulative profit: 250\n",
      "\n",
      "--- Round 3 ---\n",
      "  Manufacturer's wholesale price: 4\n",
      "  Demand in this round: 107\n",
      "  Your profit this round: 400\n",
      "  Agent's profit this round: 50\n",
      "  Your cumulative profit: 1050\n",
      "  Agent's cumulative profit: 300\n",
      "\n",
      "--- Round 4 ---\n",
      "  Manufacturer's wholesale price: 6\n",
      "  Demand in this round: 118\n",
      "  Your profit this round: 480\n",
      "  Agent's profit this round: 240\n",
      "  Your cumulative profit: 1530\n",
      "  Agent's cumulative profit: 540\n",
      "\n",
      "--- Round 5 ---\n",
      "  Manufacturer's wholesale price: 6\n",
      "Invalid input. Please enter an integer between 50 and 150. Invalid input. Please enter an integer between 50 and 150. Invalid input. Please enter an integer between 50 and 150. "
     ]
    }
   ],
   "source": [
    "# --- Game with User ---\n",
    "\n",
    "# Load trained agents\n",
    "manufacturer_agent_wholesale = QLearningAgent(env_wholesale.manufacturer_action_space)\n",
    "retailer_agent_wholesale = QLearningAgent(env_wholesale.retailer_action_space)\n",
    "manufacturer_agent_buyback = QLearningAgent(env_buyback.manufacturer_action_space)\n",
    "retailer_agent_buyback = QLearningAgent(env_buyback.retailer_action_space)\n",
    "manufacturer_agent_revenue_sharing = QLearningAgent(\n",
    "    env_revenue_sharing.manufacturer_action_space\n",
    ")\n",
    "retailer_agent_revenue_sharing = QLearningAgent(\n",
    "    env_revenue_sharing.retailer_action_space\n",
    ")\n",
    "\n",
    "manufacturer_agent_wholesale.load_agent(\"manufacturer_agent_wholesale.pkl\")\n",
    "retailer_agent_wholesale.load_agent(\"retailer_agent_wholesale.pkl\")\n",
    "manufacturer_agent_buyback.load_agent(\"manufacturer_agent_buyback.pkl\")\n",
    "retailer_agent_buyback.load_agent(\"retailer_agent_buyback.pkl\")\n",
    "manufacturer_agent_revenue_sharing.load_agent(\n",
    "    \"manufacturer_agent_revenue_sharing.pkl\"\n",
    ")\n",
    "retailer_agent_revenue_sharing.load_agent(\n",
    "    \"retailer_agent_revenue_sharing.pkl\"\n",
    ")\n",
    "\n",
    "# Get user input\n",
    "contract_type = input(\n",
    "    \"Choose a contract type (wholesale, buyback, revenue-sharing): \"\n",
    ").lower()\n",
    "\n",
    "while contract_type not in [\"wholesale\", \"buyback\", \"revenue-sharing\"]:\n",
    "    print(\"Invalid contract type. Please choose from 'wholesale', 'buyback', or 'revenue-sharing'.\")\n",
    "    contract_type = input(\n",
    "        \"Choose a contract type (wholesale, buyback, revenue-sharing): \"\n",
    "    ).lower()\n",
    "    \n",
    "role = input(\"Do you want to be the manufacturer or the retailer? \").lower()\n",
    "\n",
    "while role not in [\"manufacturer\", \"retailer\"]:\n",
    "    print(\"Invalid role. Please choose either 'manufacturer' or 'retailer'.\")\n",
    "    role = input(\"Do you want to be the manufacturer or the retailer? \").lower()\n",
    "\n",
    "# Select the environment and agents based on contract type\n",
    "if contract_type == \"wholesale\":\n",
    "    env = env_wholesale\n",
    "    manufacturer_agent = manufacturer_agent_wholesale\n",
    "    retailer_agent = retailer_agent_wholesale\n",
    "elif contract_type == \"buyback\":\n",
    "    env = env_buyback\n",
    "    manufacturer_agent = manufacturer_agent_buyback\n",
    "    retailer_agent = retailer_agent_buyback\n",
    "elif contract_type == \"revenue-sharing\":\n",
    "    env = env_revenue_sharing\n",
    "    manufacturer_agent = manufacturer_agent_revenue_sharing\n",
    "    retailer_agent = retailer_agent_revenue_sharing\n",
    "else:\n",
    "    raise ValueError(\"Invalid contract type\")\n",
    "\n",
    "# Initialize the environment\n",
    "state = env.reset()\n",
    "done = False\n",
    "total_human_profit = 0\n",
    "total_agent_profit = 0\n",
    "\n",
    "# ... (The rest of the code up to the game loop remains the same)\n",
    "\n",
    "# --- Game with User ---\n",
    "\n",
    "# Load trained agents (assuming you have already trained and saved them)\n",
    "manufacturer_agent_wholesale = QLearningAgent(env_wholesale.manufacturer_action_space)\n",
    "retailer_agent_wholesale = QLearningAgent(env_wholesale.retailer_action_space)\n",
    "manufacturer_agent_buyback = QLearningAgent(env_buyback.manufacturer_action_space)\n",
    "retailer_agent_buyback = QLearningAgent(env_buyback.retailer_action_space)\n",
    "manufacturer_agent_revenue_sharing = QLearningAgent(\n",
    "    env_revenue_sharing.manufacturer_action_space\n",
    ")\n",
    "retailer_agent_revenue_sharing = QLearningAgent(\n",
    "    env_revenue_sharing.retailer_action_space\n",
    ")\n",
    "\n",
    "manufacturer_agent_wholesale.load_agent(\"manufacturer_agent_wholesale.pkl\")\n",
    "retailer_agent_wholesale.load_agent(\"retailer_agent_wholesale.pkl\")\n",
    "manufacturer_agent_buyback.load_agent(\"manufacturer_agent_buyback.pkl\")\n",
    "retailer_agent_buyback.load_agent(\"retailer_agent_buyback.pkl\")\n",
    "manufacturer_agent_revenue_sharing.load_agent(\n",
    "    \"manufacturer_agent_revenue_sharing.pkl\"\n",
    ")\n",
    "retailer_agent_revenue_sharing.load_agent(\n",
    "    \"retailer_agent_revenue_sharing.pkl\"\n",
    ")\n",
    "\n",
    "# Get user input\n",
    "contract_type = input(\n",
    "    \"Choose a contract type (wholesale, buyback, revenue-sharing): \"\n",
    ").lower()\n",
    "\n",
    "while contract_type not in [\"wholesale\", \"buyback\", \"revenue-sharing\"]:\n",
    "    print(\"Invalid contract type. Please choose from 'wholesale', 'buyback', or 'revenue-sharing'.\")\n",
    "    contract_type = input(\n",
    "        \"Choose a contract type (wholesale, buyback, revenue-sharing): \"\n",
    "    ).lower()\n",
    "\n",
    "role = input(\"Do you want to be the manufacturer or the retailer? \").lower()\n",
    "while role not in [\"manufacturer\", \"retailer\"]:\n",
    "    print(\"Invalid role. Please choose either 'manufacturer' or 'retailer'.\")\n",
    "    role = input(\"Do you want to be the manufacturer or the retailer? \").lower()\n",
    "\n",
    "# Select the environment and agents based on contract type\n",
    "if contract_type == \"wholesale\":\n",
    "    env = env_wholesale\n",
    "    manufacturer_agent = manufacturer_agent_wholesale\n",
    "    retailer_agent = retailer_agent_wholesale\n",
    "elif contract_type == \"buyback\":\n",
    "    env = env_buyback\n",
    "    manufacturer_agent = manufacturer_agent_buyback\n",
    "    retailer_agent = retailer_agent_buyback\n",
    "elif contract_type == \"revenue-sharing\":\n",
    "    env = env_revenue_sharing\n",
    "    manufacturer_agent = manufacturer_agent_revenue_sharing\n",
    "    retailer_agent = retailer_agent_revenue_sharing\n",
    "else:\n",
    "    raise ValueError(\"Invalid contract type\")\n",
    "\n",
    "# Initialize the environment\n",
    "state = env.reset()\n",
    "done = False\n",
    "total_human_profit = 0\n",
    "total_agent_profit = 0\n",
    "\n",
    "# Game loop\n",
    "for round_num in range(1, env.max_rounds + 1):\n",
    "    print(f\"\\n--- Round {round_num} ---\")\n",
    "\n",
    "    if role == \"manufacturer\":\n",
    "        # Human's turn (manufacturer)\n",
    "        valid_action = False\n",
    "        while not valid_action:\n",
    "            try:\n",
    "                if contract_type == \"wholesale\":\n",
    "                    w = int(\n",
    "                        input(\n",
    "                            f\"Enter wholesale price (integer between {env.min_w} and {env.max_price}): \"\n",
    "                        )\n",
    "                    )\n",
    "                    human_action = w - env.min_w  # Adjust action to be in the correct range for the agent\n",
    "                    if 0 <= human_action <= env.manufacturer_action_space.n - 1:\n",
    "                        valid_action = True\n",
    "                        b = 0\n",
    "                        r = 0\n",
    "                    else:\n",
    "                        print(\"Invalid wholesale price. \", end=\"\")\n",
    "\n",
    "                elif contract_type == \"buyback\":\n",
    "                    w = int(\n",
    "                        input(\n",
    "                            f\"Enter wholesale price (integer between {env.min_w} and {env.max_price}): \"\n",
    "                        )\n",
    "                    )\n",
    "                    b = int(\n",
    "                        input(\n",
    "                            f\"Enter buyback price (integer between 0 and {env.max_price}): \"\n",
    "                        )\n",
    "                    )\n",
    "                    human_action = (w - env.min_w, b)  # Adjust action to be in the correct range for the agent\n",
    "                    if (\n",
    "                        0 <= human_action[0] <= env.manufacturer_action_space.nvec[0] - 1\n",
    "                        and 0 <= human_action[1] <= env.manufacturer_action_space.nvec[1] - 1\n",
    "                    ):\n",
    "                        valid_action = True\n",
    "                        r = 0\n",
    "                    else:\n",
    "                        print(\"Invalid wholesale or buyback price. \", end=\"\")\n",
    "\n",
    "                elif contract_type == \"revenue-sharing\":\n",
    "                    w = int(\n",
    "                        input(\n",
    "                            f\"Enter wholesale price (integer between {env.min_w} and {env.max_price}): \"\n",
    "                        )\n",
    "                    )\n",
    "                    r = int(\n",
    "                        input(\n",
    "                            f\"Enter revenue share (integer between 0 and {env.max_price}): \"\n",
    "                        )\n",
    "                    )\n",
    "                    human_action = (w - env.min_w, r)  # Adjust action to be in the correct range for the agent\n",
    "                    if (\n",
    "                        0 <= human_action[0] <= env.manufacturer_action_space.nvec[0] - 1\n",
    "                        and 0 <= human_action[1] <= env.manufacturer_action_space.nvec[1] - 1\n",
    "                    ):\n",
    "                        valid_action = True\n",
    "                        b = 0\n",
    "                    else:\n",
    "                        print(\"Invalid wholesale price or revenue share. \", end=\"\")\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid contract type\")\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter an integer. \", end=\"\")\n",
    "\n",
    "        # Update the environment based on the human's action\n",
    "        state = env.manufacturer_step(human_action)\n",
    "\n",
    "        # Agent's turn (retailer)\n",
    "        agent_action = retailer_agent.get_action(state)\n",
    "\n",
    "        # Determine the agent's stock quantity based on the action\n",
    "        optimal_stock = env.get_optimal_stock()\n",
    "        if agent_action == 0:\n",
    "            agent_stock_choice = int(round(optimal_stock * 0.8))  # Understock\n",
    "        elif agent_action == 1:\n",
    "            agent_stock_choice = int(round(optimal_stock))  # Optimal\n",
    "        elif agent_action == 2:\n",
    "            agent_stock_choice = int(round(optimal_stock * 1.2))  # Overstock\n",
    "        else:\n",
    "            agent_stock_choice = int(round(optimal_stock))\n",
    "\n",
    "        # Update the environment based on the agent's action\n",
    "        next_state, rewards, done, _ = env.retailer_step(agent_action)\n",
    "        _, _ = rewards\n",
    "\n",
    "        # Update agent (only opponent model, not Q-table during human interaction)\n",
    "        retailer_agent.update_opponent_model(human_action, state, contract_type)\n",
    "\n",
    "        # Generate random demand for the round\n",
    "        env.demand = random.randint(50, 150)\n",
    "\n",
    "        # Calculate realized profits for human (manufacturer) and agent (retailer)\n",
    "        if contract_type == \"wholesale\":\n",
    "            human_profit = (w - env.min_w) * min(agent_stock_choice, env.demand)\n",
    "            agent_profit = (\n",
    "                12 * min(agent_stock_choice, env.demand) - w * agent_stock_choice\n",
    "            )\n",
    "\n",
    "        elif contract_type == \"buyback\":\n",
    "            human_profit = (\n",
    "                (w - env.min_w) * min(agent_stock_choice, env.demand)\n",
    "                - b * (agent_stock_choice - min(agent_stock_choice, env.demand))\n",
    "            )\n",
    "            agent_profit = (\n",
    "                12 * min(agent_stock_choice, env.demand)\n",
    "                - w * agent_stock_choice\n",
    "                + b * (agent_stock_choice - min(agent_stock_choice, env.demand))\n",
    "            )\n",
    "\n",
    "        elif contract_type == \"revenue-sharing\":\n",
    "            human_profit = (\n",
    "                (w - env.min_w) * min(agent_stock_choice, env.demand)\n",
    "                + r * (agent_stock_choice - min(agent_stock_choice, env.demand))\n",
    "            )\n",
    "            agent_profit = (\n",
    "                12 * min(agent_stock_choice, env.demand)\n",
    "                - w * agent_stock_choice\n",
    "                - r * (agent_stock_choice - min(agent_stock_choice, env.demand))\n",
    "            )\n",
    "\n",
    "        # Update total profits\n",
    "        total_human_profit += human_profit\n",
    "        total_agent_profit += agent_profit\n",
    "\n",
    "    else:  # role == \"retailer\"\n",
    "        # Agent's turn (manufacturer)\n",
    "        manufacturer_action = manufacturer_agent.get_action(state)\n",
    "\n",
    "        # Update the environment based on the agent's action\n",
    "        state = env.manufacturer_step(manufacturer_action)\n",
    "\n",
    "        # Get the manufacturer's decision variables from the state\n",
    "        w, b, r = state\n",
    "\n",
    "        # Human's turn (retailer)\n",
    "        # Provide the manufacturer's decision to the human player\n",
    "        if contract_type == \"wholesale\":\n",
    "            print(f\"  Manufacturer's wholesale price: {w}\")\n",
    "        elif contract_type == \"buyback\":\n",
    "            print(f\"  Manufacturer's wholesale price: {w}, Buyback price: {b}\")\n",
    "        elif contract_type == \"revenue-sharing\":\n",
    "            print(f\"  Manufacturer's wholesale price: {w}, Revenue share: {r}\")\n",
    "\n",
    "        # Get human's stock decision\n",
    "        valid_stock = False\n",
    "        while not valid_stock:\n",
    "            try:\n",
    "                stock_choice = int(\n",
    "                    input(\n",
    "                        f\"Enter retailer stock (integer between 50 and {env.max_stock}): \"\n",
    "                    )\n",
    "                )\n",
    "                if 50 <= stock_choice <= env.max_stock:\n",
    "                    valid_stock = True\n",
    "                else:\n",
    "                    print(\"Invalid stock. \", end=\"\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter an integer between 50 and 150. \", end=\"\")\n",
    "\n",
    "        # Convert stock choice to action (0, 1, or 2)\n",
    "        optimal_stock = env.get_optimal_stock()\n",
    "        if stock_choice <= optimal_stock * 0.8:\n",
    "            human_action = 0  # Understocking\n",
    "        elif stock_choice <= optimal_stock * 1.2:\n",
    "            human_action = 1  # Optimal\n",
    "        else:\n",
    "            human_action = 2  # Overstocking\n",
    "\n",
    "        # Update the environment based on the human's action\n",
    "        # Note: The environment still uses the 0, 1, 2 representation for internal calculations\n",
    "        next_state, rewards, done, _ = env.retailer_step(human_action)\n",
    "        _, _ = rewards\n",
    "\n",
    "        # Update agent (only opponent model, not Q-table during human interaction)\n",
    "        manufacturer_agent.update_opponent_model(human_action, state, contract_type)\n",
    "\n",
    "        # Generate random demand for the round\n",
    "        env.demand = random.randint(50, 150)\n",
    "\n",
    "        # Calculate realized profits for human (retailer) and agent (manufacturer)\n",
    "        if contract_type == \"wholesale\":\n",
    "            human_profit = 12 * min(stock_choice, env.demand) - w * stock_choice\n",
    "            agent_profit = (w - env.min_w) * min(stock_choice, env.demand)\n",
    "        elif contract_type == \"buyback\":\n",
    "            human_profit = (\n",
    "                12 * min(stock_choice, env.demand)\n",
    "                - w * stock_choice\n",
    "                + b * (stock_choice - min(stock_choice, env.demand))\n",
    "            )\n",
    "            agent_profit = (\n",
    "                (w - env.min_w) * min(stock_choice, env.demand)\n",
    "                - b * (stock_choice - min(stock_choice, env.demand))\n",
    "            )\n",
    "        elif contract_type == \"revenue-sharing\":\n",
    "            human_profit = (\n",
    "                12 * min(stock_choice, env.demand)\n",
    "                - w * stock_choice\n",
    "                - r * (stock_choice - min(stock_choice, env.demand))\n",
    "            )\n",
    "            agent_profit = (\n",
    "                (w - env.min_w) * min(stock_choice, env.demand)\n",
    "                + r * (stock_choice - min(stock_choice, env.demand))\n",
    "            )\n",
    "        else:\n",
    "            human_profit = 0\n",
    "            agent_profit = 0\n",
    "\n",
    "        # Update total profits\n",
    "        total_human_profit += human_profit\n",
    "        total_agent_profit += agent_profit\n",
    "\n",
    "    print(f\"  Demand in this round: {env.demand}\")\n",
    "    print(f\"  Your profit this round: {human_profit}\")\n",
    "    print(f\"  Agent's profit this round: {agent_profit}\")\n",
    "    print(f\"  Your cumulative profit: {total_human_profit}\")\n",
    "    print(f\"  Agent's cumulative profit: {total_agent_profit}\")\n",
    "\n",
    "    state = next_state  # Update state for the next round\n",
    "\n",
    "print(\"\\nGame Over!\")\n",
    "print(f\"Final Score - You: {total_human_profit}, Agent: {total_agent_profit}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
