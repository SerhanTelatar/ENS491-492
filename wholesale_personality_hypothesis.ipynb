{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\telat\\AppData\\Local\\Temp\\ipykernel_59028\\839069531.py:5: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  contract_data = pd.read_csv('Notebooks\\experiment\\curr_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Period</th>\n",
       "      <th>Player ID</th>\n",
       "      <th>Demand</th>\n",
       "      <th>Wholesale p.</th>\n",
       "      <th>Player ID.1</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Leftovers</th>\n",
       "      <th>Unmet_Demand</th>\n",
       "      <th>...</th>\n",
       "      <th>Expected_Leftovers</th>\n",
       "      <th>Expected Retailer Profit</th>\n",
       "      <th>Expected Mfg Profit</th>\n",
       "      <th>Expected Mfg. Profit Share</th>\n",
       "      <th>Predicted Sales</th>\n",
       "      <th>Predicted Leftovers</th>\n",
       "      <th>Predicted Retailer Profit</th>\n",
       "      <th>Predicted Mfg Profit</th>\n",
       "      <th>Realized Retailer Profit</th>\n",
       "      <th>Predicted Mfg. Profit Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Manufacturer 1</td>\n",
       "      <td>122</td>\n",
       "      <td>8</td>\n",
       "      <td>Retailer 1</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>23.45</td>\n",
       "      <td>234.6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.561167</td>\n",
       "      <td>77.72</td>\n",
       "      <td>5.28</td>\n",
       "      <td>268.64</td>\n",
       "      <td>415</td>\n",
       "      <td>240</td>\n",
       "      <td>0.607045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Manufacturer 1</td>\n",
       "      <td>144</td>\n",
       "      <td>7</td>\n",
       "      <td>Retailer 1</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>15.35</td>\n",
       "      <td>347.8</td>\n",
       "      <td>320</td>\n",
       "      <td>0.479185</td>\n",
       "      <td>82.80</td>\n",
       "      <td>8.20</td>\n",
       "      <td>356.60</td>\n",
       "      <td>364</td>\n",
       "      <td>400</td>\n",
       "      <td>0.505135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Manufacturer 1</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>Retailer 1</td>\n",
       "      <td>80</td>\n",
       "      <td>57</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.35</td>\n",
       "      <td>347.8</td>\n",
       "      <td>320</td>\n",
       "      <td>0.479185</td>\n",
       "      <td>82.80</td>\n",
       "      <td>8.20</td>\n",
       "      <td>356.60</td>\n",
       "      <td>364</td>\n",
       "      <td>124</td>\n",
       "      <td>0.505135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Manufacturer 1</td>\n",
       "      <td>149</td>\n",
       "      <td>9</td>\n",
       "      <td>Retailer 1</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>24.00</td>\n",
       "      <td>153.0</td>\n",
       "      <td>306</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>72.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>189.00</td>\n",
       "      <td>450</td>\n",
       "      <td>153</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Manufacturer 1</td>\n",
       "      <td>135</td>\n",
       "      <td>8</td>\n",
       "      <td>Retailer 1</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>23.45</td>\n",
       "      <td>234.6</td>\n",
       "      <td>300</td>\n",
       "      <td>0.561167</td>\n",
       "      <td>77.72</td>\n",
       "      <td>5.28</td>\n",
       "      <td>268.64</td>\n",
       "      <td>415</td>\n",
       "      <td>240</td>\n",
       "      <td>0.607045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment  Period       Player ID  Demand  Wholesale p. Player ID.1  \\\n",
       "0           1       1  Manufacturer 1     122             8  Retailer 1   \n",
       "1           1       2  Manufacturer 1     144             7  Retailer 1   \n",
       "2           1       3  Manufacturer 1      57             7  Retailer 1   \n",
       "3           1       4  Manufacturer 1     149             9  Retailer 1   \n",
       "4           1       5  Manufacturer 1     135             8  Retailer 1   \n",
       "\n",
       "   Stock  Sales  Leftovers  Unmet_Demand  ...  Expected_Leftovers  \\\n",
       "0     60     60          0            62  ...               23.45   \n",
       "1     80     80          0            64  ...               15.35   \n",
       "2     80     57         23             0  ...               15.35   \n",
       "3     51     51          0            98  ...               24.00   \n",
       "4     60     60          0            75  ...               23.45   \n",
       "\n",
       "   Expected Retailer Profit  Expected Mfg Profit  Expected Mfg. Profit Share  \\\n",
       "0                     234.6                  300                    0.561167   \n",
       "1                     347.8                  320                    0.479185   \n",
       "2                     347.8                  320                    0.479185   \n",
       "3                     153.0                  306                    0.666667   \n",
       "4                     234.6                  300                    0.561167   \n",
       "\n",
       "   Predicted Sales  Predicted Leftovers  Predicted Retailer Profit  \\\n",
       "0            77.72                 5.28                     268.64   \n",
       "1            82.80                 8.20                     356.60   \n",
       "2            82.80                 8.20                     356.60   \n",
       "3            72.00                 3.00                     189.00   \n",
       "4            77.72                 5.28                     268.64   \n",
       "\n",
       "   Predicted Mfg Profit  Realized Retailer Profit  Predicted Mfg. Profit Share  \n",
       "0                   415                       240                     0.607045  \n",
       "1                   364                       400                     0.505135  \n",
       "2                   364                       124                     0.505135  \n",
       "3                   450                       153                     0.704225  \n",
       "4                   415                       240                     0.607045  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "survey_data = pd.read_csv('adjusted_reponse_survey.csv')\n",
    "contract_data = pd.read_csv('Notebooks\\experiment\\curr_data.csv')\n",
    "\n",
    "from scipy.stats import wilcoxon, shapiro\n",
    "\n",
    "# Merge the datasets on player names for analysis\n",
    "merged_data = contract_data.merge(\n",
    "    survey_data, how='left', left_on='Player ID', right_on='PLAYER NAME'\n",
    ")\n",
    "\n",
    "contract_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Risk Averse Coefficient'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\telat\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Risk Averse Coefficient'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m contract_data\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m      8\u001b[0m     survey_data, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlayer ID\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPLAYER NAME\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Check if the Risk Averse Coefficient values are now successfully transferred in the merged dataset\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRisk Averse Coefficient\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum(), merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRisk Averse Coefficient\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[0;32m     15\u001b[0m merged_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\telat\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\telat\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Risk Averse Coefficient'"
     ]
    }
   ],
   "source": [
    "# Standardize identifiers in both datasets to facilitate merging\n",
    "\n",
    "# Convert 'Player ID' in contract_data to lowercase and remove spaces to match survey_data\n",
    "contract_data['Player ID'] = contract_data['Player ID'].str.replace(\" \", \"\").str.lower()\n",
    "\n",
    "# Re-attempt merging on the standardized 'Player ID' and 'PLAYER NAME' columns\n",
    "merged_data = contract_data.merge(\n",
    "    survey_data, how='left', left_on='Player ID', right_on='PLAYER NAME'\n",
    ")\n",
    "\n",
    "# Check if the Risk Averse Coefficient values are now successfully transferred in the merged dataset\n",
    "merged_data['Risk Averse Coefficient'].isna().sum(), merged_data['Risk Averse Coefficient'].describe()\n",
    "\n",
    "\n",
    "merged_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk Aversion Hypothesis Test: 3.0 0.1\n",
      "Mean Stock Difference - Top Risk Averse: -33.25\n",
      "Mean Stock Difference - Bottom Risk Averse: -4.75\n",
      "The top 4 risk-averse individuals tend to underorder compared to the bottom 4.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hypothesis 1: Does Risk Aversion affect the difference between actual and optimal stock levels?\n",
    "# Null Hypothesis (H0): There is no significant difference in the stock-keeping behavior of high-risk-averse and low-risk-averse individuals.\n",
    "# Alternative Hypothesis (H1): There is a significant difference in the stock-keeping behavior based on risk aversion.\n",
    "\n",
    "from scipy.stats import mannwhitneyu, shapiro\n",
    "\n",
    "# Function to get the top and bottom 4 based on a given column\n",
    "def get_top_bottom_4(data, column):\n",
    "    sorted_data = data.sort_values(by=column)\n",
    "    top_4 = sorted_data.tail(4)\n",
    "    bottom_4 = sorted_data.head(4)\n",
    "    return top_4, bottom_4\n",
    "\n",
    "# Example for Risk Aversion and Stock Level Difference\n",
    "top_risk_averse, bottom_risk_averse = get_top_bottom_4(merged_data, 'Risk Averse Coefficient')\n",
    "\n",
    "# Calculate the difference between realized and optimal stock for both groups\n",
    "top_risk_diff = top_risk_averse['Stock'] - top_risk_averse['Optimal_Stock']\n",
    "bottom_risk_diff = bottom_risk_averse['Stock'] - bottom_risk_averse['Optimal_Stock']\n",
    "\n",
    "# Conduct Mann-Whitney U test\n",
    "test_stat, p_value = mannwhitneyu(top_risk_diff.dropna(), bottom_risk_diff.dropna(), alternative='less')\n",
    "print(\"Risk Aversion Hypothesis Test:\", test_stat, p_value)\n",
    "\n",
    "# Determine the direction of the difference\n",
    "mean_top_risk = top_risk_diff.mean()\n",
    "mean_bottom_risk = bottom_risk_diff.mean()\n",
    "\n",
    "print(f\"Mean Stock Difference - Top Risk Averse: {mean_top_risk:.2f}\")\n",
    "print(f\"Mean Stock Difference - Bottom Risk Averse: {mean_bottom_risk:.2f}\")\n",
    "\n",
    "if mean_top_risk > mean_bottom_risk:\n",
    "    print(\"The top 4 risk-averse individuals tend to overorder compared to the bottom 4.\")\n",
    "elif mean_top_risk < mean_bottom_risk:\n",
    "    print(\"The top 4 risk-averse individuals tend to underorder compared to the bottom 4.\")\n",
    "else:\n",
    "    print(\"No directional difference observed between the top and bottom risk-averse groups.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98215.5, 0.555089882203615)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct Wilcoxon test (since normality might not hold)\n",
    "_, high_risk_pval = shapiro(high_risk_diff.dropna())\n",
    "_, low_risk_pval = shapiro(low_risk_diff.dropna())\n",
    "\n",
    "# Re-attempting with the Mann-Whitney U test for independent samples with unequal sizes\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Conduct Mann-Whitney U test as an alternative to Wilcoxon due to unequal sample sizes\n",
    "test_stat, p_value = mannwhitneyu(high_risk_diff.dropna(), low_risk_diff.dropna(), alternative='two-sided')\n",
    "\n",
    "# (98215.5, 0.555089882203615)\n",
    "test_stat, p_value\n",
    "\n",
    "\"\"\"\n",
    "The Mann-Whitney U test results in a p-value of approximately 0.555, indicating no statistically significant difference between high-risk-averse and low-risk-averse groups \n",
    "in terms of their deviations from the optimal stock level. This suggests that risk aversion may not significantly impact stocking decisions in this experiment.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107778.5, 0.003582084997420401)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis Test: Impact of Self-Esteem on Deviation from Optimal Stock Levels\n",
    "# Null Hypothesis (H0): There is no significant difference in the deviation from optimal stock level between high and low self-esteem groups.\n",
    "# Alternative Hypothesis (H1): There is a significant difference in deviation based on self-esteem.\n",
    "\n",
    "# Median split for self-esteem\n",
    "esteem_median = merged_data['Self Esteem Average'].median()\n",
    "high_esteem = merged_data[merged_data['Self Esteem Average'] >= esteem_median]\n",
    "low_esteem = merged_data[merged_data['Self Esteem Average'] < esteem_median]\n",
    "\n",
    "# Calculate stock deviation from optimal stock for both groups\n",
    "high_esteem_diff = high_esteem['Stock'] - high_esteem['Optimal_Stock']\n",
    "low_esteem_diff = low_esteem['Stock'] - low_esteem['Optimal_Stock']\n",
    "\n",
    "# Conduct Mann-Whitney U test to account for unequal sample sizes\n",
    "test_stat, p_value = mannwhitneyu(high_esteem_diff.dropna(), low_esteem_diff.dropna(), alternative='two-sided')\n",
    "\n",
    "test_stat, p_value\n",
    "\n",
    "\"\"\"\n",
    "The Mann-Whitney U test yields a p-value of approximately 0.0036, indicating a statistically significant \n",
    "difference in deviations from optimal stock levels between high and low self-esteem groups. \n",
    "This suggests that self-esteem may indeed influence ordering behavior, with higher \n",
    "self-esteem potentially aligning more closely with optimal stock levels.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109357.0, 0.00019240731573129556)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis Test: Influence of Fairness Index on Wholesale Price Acceptance\n",
    "# Null Hypothesis (H0): There is no significant difference in the reaction to wholesale price changes based on fairness index.\n",
    "# Alternative Hypothesis (H1): There is a significant difference in wholesale price acceptance based on fairness.\n",
    "\n",
    "# Median split for fairness index\n",
    "fairness_median = merged_data['Fairness Index'].median()\n",
    "high_fairness = merged_data[merged_data['Fairness Index'] >= fairness_median]\n",
    "low_fairness = merged_data[merged_data['Fairness Index'] < fairness_median]\n",
    "\n",
    "# Calculate wholesale price for both groups\n",
    "high_fairness_wholesale = high_fairness['Wholesale p.']\n",
    "low_fairness_wholesale = low_fairness['Wholesale p.']\n",
    "\n",
    "# Conduct Mann-Whitney U test for wholesale price acceptance in both groups\n",
    "test_stat, p_value = mannwhitneyu(high_fairness_wholesale.dropna(), low_fairness_wholesale.dropna(), alternative='two-sided')\n",
    "\n",
    "test_stat, p_value\n",
    "\n",
    "\"\"\"\n",
    "The Mann-Whitney U test results in a p-value of approximately 0.0002, indicating a statistically significant difference \n",
    "in reactions to wholesale price changes based on fairness index. This suggests that individuals with higher fairness indexes\n",
    " may respond differently to price fluctuations compared to those with lower fairness indexes, potentially being more \n",
    " resistant to or influenced by changes in wholesale prices.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91717.5, 0.1775270055865822)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis Test: Regret Sensitivity and Over/Under-Stocking Behavior\n",
    "# Null Hypothesis (H0): There is no significant difference in over/under-stocking behavior based on regret sensitivity.\n",
    "# Alternative Hypothesis (H1): There is a significant difference in over/under-stocking based on regret sensitivity.\n",
    "\n",
    "# Median split for Regret Scale\n",
    "regret_median = merged_data['Regret Scale Average'].median()\n",
    "high_regret = merged_data[merged_data['Regret Scale Average'] >= regret_median]\n",
    "low_regret = merged_data[merged_data['Regret Scale Average'] < regret_median]\n",
    "\n",
    "# Calculate over/under-stocking for both groups\n",
    "high_regret_diff = high_regret['Stock'] - high_regret['Optimal_Stock']\n",
    "low_regret_diff = low_regret['Stock'] - low_regret['Optimal_Stock']\n",
    "\n",
    "# Conduct Mann-Whitney U test for over/under-stocking behavior based on regret sensitivity\n",
    "test_stat, p_value = mannwhitneyu(high_regret_diff.dropna(), low_regret_diff.dropna(), alternative='two-sided')\n",
    "\n",
    "test_stat, p_value\n",
    "\"\"\"\n",
    "The Mann-Whitney U test yields a p-value of approximately 0.178, indicating no statistically significant difference\n",
    " in over- or under-stocking behavior between high and low regret-sensitive participants. \n",
    "This suggests that regret sensitivity may not have a strong impact on deviations from the optimal stock level.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71593.5, 0.011093701206110461)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis Test: Fairness Index and Retailer Profit Share\n",
    "# Null Hypothesis (H0): There is no significant difference in retailer profit share based on fairness index.\n",
    "# Alternative Hypothesis (H1): There is a significant difference in retailer profit share based on fairness index.\n",
    "\n",
    "# Median split for fairness index\n",
    "fairness_median = merged_data['Fairness Index'].median()\n",
    "high_fairness = merged_data[merged_data['Fairness Index'] >= fairness_median]\n",
    "low_fairness = merged_data[merged_data['Fairness Index'] < fairness_median]\n",
    "\n",
    "# Calculate realized retailer profit share for both groups\n",
    "high_fairness_profit_share = high_fairness['Realized Retailer Profit'] / (\n",
    "    high_fairness['Realized Retailer Profit'] + high_fairness['Realized_Mfg_Profit'])\n",
    "low_fairness_profit_share = low_fairness['Realized Retailer Profit'] / (\n",
    "    low_fairness['Realized Retailer Profit'] + low_fairness['Realized_Mfg_Profit'])\n",
    "\n",
    "# Conduct Mann-Whitney U test for retailer profit share based on fairness index\n",
    "test_stat, p_value = mannwhitneyu(high_fairness_profit_share.dropna(), low_fairness_profit_share.dropna(), alternative='two-sided')\n",
    "\n",
    "test_stat, p_value\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The Mann-Whitney U test gives a p-value of approximately 0.011, indicating a statistically significant difference in retailer profit share between participants with high and low fairness indexes. \n",
    "This suggests that fairness may indeed influence the distribution of profits between the retailer and manufacturer, with higher fairness potentially leading to a more balanced profit share.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89551.0, 0.08584266993168418)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis Test: Risk Aversion and Demand Responsiveness\n",
    "# Null Hypothesis (H0): There is no significant difference in demand responsiveness based on risk aversion.\n",
    "# Alternative Hypothesis (H1): There is a significant difference in demand responsiveness based on risk aversion.\n",
    "\n",
    "# Calculate responsiveness to demand by taking the absolute difference between demand and stock for each group\n",
    "high_risk_demand_response = abs(high_risk_averse['Demand'] - high_risk_averse['Stock'])\n",
    "low_risk_demand_response = abs(low_risk_averse['Demand'] - low_risk_averse['Stock'])\n",
    "\n",
    "# Conduct Mann-Whitney U test for demand responsiveness based on risk aversion\n",
    "test_stat, p_value = mannwhitneyu(high_risk_demand_response.dropna(), low_risk_demand_response.dropna(), alternative='two-sided')\n",
    "\n",
    "test_stat, p_value\n",
    "\n",
    "\"\"\"\n",
    "The Mann-Whitney U test yields a p-value of approximately 0.086, which does not indicate a statistically significant difference in demand responsiveness between \n",
    "high and low risk-averse participants. This suggests that risk aversion may not strongly impact how participants adjust their stock in response to demand changes.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
